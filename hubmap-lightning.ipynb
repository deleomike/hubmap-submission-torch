{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import torchmetrics\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms as py_transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lovasz import lovasz_hinge\n",
    "from albumentations import *\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sz = 256\n",
    "\n",
    "def getBatchSize(sz):\n",
    "\n",
    "    # 48 for 512\n",
    "    if sz == 256:\n",
    "        bs = 64\n",
    "    elif sz == 512:\n",
    "        bs = 48 #batch size\n",
    "    elif sz == 1024:\n",
    "        bs = 12 #batch size\n",
    "    else:\n",
    "        bs = 12\n",
    "        \n",
    "    return bs\n",
    "\n",
    "def getPaths(sz):\n",
    "    TRAIN = \"./data/{}x{}/train/\".format(sz, sz)\n",
    "    MASKS = \"./data/{}x{}/masks/\".format(sz, sz)\n",
    "    # TRAIN = \"./kaggle/data/{}x{}/train/\".format(sz, sz)\n",
    "    # MASKS = \"./data/{}x{}/masks/\".format(sz, sz)\n",
    "    LABELS = \"./hubmap-kidney-segmentation/train.csv\"\n",
    "    \n",
    "    return TRAIN, MASKS, LABELS\n",
    "\n",
    "# 12 for 1024\n",
    "# Input Parameters\n",
    "nfolds = 4\n",
    "fold = 0\n",
    "SEED = 2020\n",
    "NUM_WORKERS = 16\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.backends.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # the following line gives ~10% speedup\n",
    "    # but may lead to some stochasticity in the results\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "def getStats(sz):\n",
    "\n",
    "    # https://www.kaggle.com/iafoss/256x256-images\n",
    "    if sz == 256:\n",
    "        mean = np.array([0.62950801, 0.45658695, 0.67636472])\n",
    "        std = np.array([0.15937661, 0.21920461, 0.14160065])\n",
    "\n",
    "    # 512x512\n",
    "    elif sz == 512:\n",
    "        mean = np.array([0.64246083, 0.48809628, 0.68370845])\n",
    "        std = np.array([0.17817486, 0.24006252, 0.16265069])\n",
    "\n",
    "    # 1024x1024\n",
    "    else:\n",
    "        mean = np.array([0.63244577, 0.49794695, 0.66810544])\n",
    "        std = np.array([0.22345657, 0.26747085, 0.21520419])\n",
    "        \n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def img2tensor(img, dtype: np.dtype = np.float32):\n",
    "    if img.ndim == 2: img = np.expand_dims(img, 2)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False)).to(dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self, mean, std, train_path, mask_path, label_path, fold=fold, train=True, tfms=None, cache=True):\n",
    "        self.TRAIN = train_path\n",
    "        self.LABELS = label_path\n",
    "        self.MASKS = mask_path\n",
    "        \n",
    "        \n",
    "        ids = pd.read_csv(self.LABELS).id.values\n",
    "        kf = KFold(n_splits=nfolds, random_state=SEED, shuffle=True)\n",
    "        ids = set(ids[list(kf.split(ids))[fold][0 if train else 1]])\n",
    "        self.fnames = [fname for fname in os.listdir(self.TRAIN) if fname.split('_')[0] in ids]\n",
    "        self.train = train\n",
    "        self.tfms = tfms\n",
    "        self.cache = cache\n",
    "        \n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "        if self.cache:\n",
    "            self.images = [cv2.cvtColor(cv2.imread(os.path.join(self.TRAIN, fname)), cv2.COLOR_BGR2RGB)\n",
    "                             for fname in tqdm(self.fnames)]\n",
    "            self.masks = [cv2.imread(os.path.join(self.MASKS, fname), cv2.IMREAD_GRAYSCALE)\n",
    "                              for fname in tqdm(self.fnames)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "\n",
    "        if self.cache:\n",
    "            img = self.images[idx]\n",
    "            mask = self.masks[idx]\n",
    "        else:\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.TRAIN, fname)), cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(os.path.join(self.MASKS, fname), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.tfms is not None:\n",
    "            augmented = self.tfms(image=img, mask=mask)\n",
    "            img, mask = augmented['image'], augmented['mask']\n",
    "        return py_transforms.ToTensor()(img), py_transforms.ToTensor()(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aug(p=1.0):\n",
    "    return Compose([\n",
    "        HorizontalFlip(),\n",
    "        VerticalFlip(),\n",
    "        RandomRotate90(),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.9,\n",
    "                         border_mode=cv2.BORDER_REFLECT),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.3),\n",
    "        OneOf([\n",
    "            HueSaturationValue(10, 15, 10),\n",
    "            CLAHE(clip_limit=2),\n",
    "            RandomBrightnessContrast(),\n",
    "        ], p=0.3),\n",
    "    ], p=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f70adeaeb38>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f70adeaeac8>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createDataset(size, folds, fold, train, tfms=None):\n",
    "    mean, std = getStats(size)\n",
    "    \n",
    "    train_path, mask_path, label_path = getPaths(size)\n",
    "    \n",
    "    ds = HuBMAPDataset(mean=mean, std=std, train_path=train_path, mask_path=mask_path, label_path=label_path,\n",
    "                       fold=fold, tfms=tfms, cache=False, train=train)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "def createDataLoaders(size, folds, fold):\n",
    "    \n",
    "    ds_train = createDataset(size=size, folds=folds, fold=fold, train=True, tfms=get_aug())\n",
    "    ds_val = createDataset(size=size, folds=folds, fold=fold, train=False)\n",
    "    \n",
    "    bs = getBatchSize(size)\n",
    "    \n",
    "    train_loader = DataLoader(ds_train, batch_size=bs, num_workers=20)\n",
    "    val_loader = DataLoader(ds_val, batch_size=bs, num_workers=20)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "createDataset(256, 4, False, 0)\n",
    "\n",
    "createDataLoaders(256, 4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubmapSystem(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, learning_rate=1.3182567385564074e-07):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "#         print(\"Learning Rate: \", self.learning_rate)\n",
    "        \n",
    "        self.num_classes = 1\n",
    "        \n",
    "        self.epoch_dice = []\n",
    "        \n",
    "        \n",
    "#         aux_params=dict(\n",
    "#             pooling='avg',             # one of 'avg', 'max'\n",
    "#             dropout=0.5,               # dropout ratio, default is None\n",
    "#             activation='sigmoid',      # activation function, default is None\n",
    "#             classes=self.num_classes,                 # define number of output labels\n",
    "#         )\n",
    "        \n",
    "        self.model = smp.FPN(\n",
    "            encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "            encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "            in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "            classes=self.num_classes,                      # model output channels (number of classes in your dataset)\n",
    "            decoder_dropout=0.1,\n",
    "        )\n",
    "        \n",
    "#         self.model.to(dtype=torch.float16)\n",
    "        \n",
    "#         if self.precision == 16:\n",
    "            \n",
    "#             self.model.to(dtype=torch.float16)\n",
    "#         else:\n",
    "#             self.model.to(dtype=torch.float32)\n",
    "        \n",
    "#         for name, param in self.model.named_parameters():\n",
    "#             param.requires_grad = False\n",
    "            \n",
    "#         for name, param in self.model.segmentation_head.named_parameters():\n",
    "#             param.requires_grad = True\n",
    "        \n",
    "#         for name, parameter in self.model.named_parameters():\n",
    "#             print(name, parameter.requires_grad)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        res = self.model(x)\n",
    "        return res\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "#         print(y_hat)\n",
    "        loss = self.symmetric_lovasz(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"dice\", self.dice_metric(y_hat, y), prog_bar=True)\n",
    "        \n",
    "        self.epoch_dice.append(self.dice_metric(y_hat, y).item())\n",
    "        \n",
    "#         print(torchmetrics.functional.dice_score(y_hat, y))\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self, outputs):\n",
    "        avg = np.mean(self.epoch_dice)\n",
    "        self.log(\"MEAN DICE\", avg, prog_bar=True)\n",
    "        self.epoch_dice = []\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        print(\"yhat:\", y_hat)\n",
    "        print(\"y\", y)\n",
    "        loss = self.symmetric_lovasz(y_hat, y)\n",
    "        print(loss)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_dice\", self.dice_metric(y_hat, y), prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "        \n",
    "    def symmetric_lovasz(self, outputs, targets):\n",
    "        return 0.5*(lovasz_hinge(outputs, targets) + lovasz_hinge(-outputs, 1.0 - targets))\n",
    "    \n",
    "    def dice_metric(self, y_hat, y):\n",
    "        return torchmetrics.functional.f1(y_hat, y, num_classes=self.num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_train = HuBMAPDataset(fold=0, train=True, tfms=get_aug(), cache=False)\n",
    "#ds_val = HuBMAPDataset(fold=0, train=False, cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = DataLoader(ds_train, batch_size=bs, num_workers=16)\n",
    "#val_loader = DataLoader(ds_val, batch_size=bs, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#system = HubmapSystem()\n",
    "#trainer = pl.Trainer(gpus=1, precision=16, deterministic=True,\n",
    "#                     benchmark=True, check_val_every_n_epoch=1, accumulate_grad_batches=22)\n",
    "#trainer.fit(system, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | FPN  | 65.7 M\n",
      "-------------------------------\n",
      "65.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "65.7 M    Total params\n",
      "262.663   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat: tensor([[[[-2.6562, -2.9238, -3.1895,  ..., -4.7109, -4.4414, -4.1719],\n",
      "          [-2.7402, -2.9941, -3.2480,  ..., -4.8672, -4.6016, -4.3320],\n",
      "          [-2.8223, -3.0645, -3.3066,  ..., -5.0234, -4.7578, -4.4922],\n",
      "          ...,\n",
      "          [-4.4141, -4.6836, -4.9492,  ..., -4.8828, -5.0000, -5.1133],\n",
      "          [-4.3008, -4.5586, -4.8164,  ..., -4.8008, -4.9258, -5.0547],\n",
      "          [-4.1875, -4.4375, -4.6836,  ..., -4.7188, -4.8555, -4.9961]]],\n",
      "\n",
      "\n",
      "        [[[-2.8672, -3.0703, -3.2734,  ..., -5.8594, -5.5898, -5.3203],\n",
      "          [-2.8906, -3.0977, -3.3066,  ..., -6.1406, -5.9180, -5.6953],\n",
      "          [-2.9160, -3.1270, -3.3379,  ..., -6.4219, -6.2461, -6.0703],\n",
      "          ...,\n",
      "          [-5.0742, -5.3789, -5.6836,  ..., -0.5928, -0.6260, -0.6587],\n",
      "          [-4.8711, -5.1562, -5.4375,  ..., -0.6318, -0.5850, -0.5381],\n",
      "          [-4.6680, -4.9297, -5.1953,  ..., -0.6704, -0.5435, -0.4170]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2467,  0.4019,  0.5571,  ..., -3.9785, -4.0586, -4.1367],\n",
      "          [ 0.2256,  0.3909,  0.5562,  ..., -3.9941, -4.1094, -4.2188],\n",
      "          [ 0.2046,  0.3799,  0.5552,  ..., -4.0117, -4.1562, -4.3047],\n",
      "          ...,\n",
      "          [-4.0117, -3.9727, -3.9355,  ..., -5.3516, -5.2695, -5.1836],\n",
      "          [-4.1016, -4.0898, -4.0742,  ..., -5.2930, -5.1719, -5.0508],\n",
      "          [-4.1914, -4.2031, -4.2148,  ..., -5.2344, -5.0781, -4.9180]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.4531, -6.6445, -6.8398,  ..., -6.4297, -6.2500, -6.0703],\n",
      "          [-6.5586, -6.7578, -6.9531,  ..., -6.4805, -6.3320, -6.1836],\n",
      "          [-6.6680, -6.8672, -7.0664,  ..., -6.5273, -6.4141, -6.2969],\n",
      "          ...,\n",
      "          [-6.8555, -6.9297, -7.0000,  ..., -6.4375, -6.3789, -6.3203],\n",
      "          [-6.7070, -6.7812, -6.8594,  ..., -6.3594, -6.2812, -6.2031],\n",
      "          [-6.5586, -6.6367, -6.7188,  ..., -6.2812, -6.1836, -6.0859]]],\n",
      "\n",
      "\n",
      "        [[[-5.7422, -5.7656, -5.7891,  ..., -6.2227, -6.1641, -6.1055],\n",
      "          [-5.9023, -5.9961, -6.0898,  ..., -6.2656, -6.1680, -6.0742],\n",
      "          [-6.0664, -6.2266, -6.3906,  ..., -6.3047, -6.1719, -6.0391],\n",
      "          ...,\n",
      "          [-5.7773, -5.8984, -6.0195,  ..., -6.5469, -6.4922, -6.4336],\n",
      "          [-5.6680, -5.7461, -5.8203,  ..., -6.2305, -6.1484, -6.0625],\n",
      "          [-5.5625, -5.5938, -5.6211,  ..., -5.9180, -5.8008, -5.6875]]],\n",
      "\n",
      "\n",
      "        [[[-5.8516, -5.8672, -5.8789,  ..., -7.6250, -7.4297, -7.2305],\n",
      "          [-5.9258, -5.9453, -5.9688,  ..., -7.6133, -7.4258, -7.2383],\n",
      "          [-5.9961, -6.0273, -6.0586,  ..., -7.6016, -7.4258, -7.2461],\n",
      "          ...,\n",
      "          [-6.3125, -6.6367, -6.9570,  ..., -7.5391, -7.3945, -7.2500],\n",
      "          [-6.2109, -6.5742, -6.9414,  ..., -7.4102, -7.2461, -7.0820],\n",
      "          [-6.1055, -6.5156, -6.9258,  ..., -7.2812, -7.0977, -6.9141]]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "y tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor(nan, device='cuda:0')\n",
      "yhat: tensor([[[[-4.3047, -4.3867, -4.4648,  ..., -6.6602, -6.8438, -7.0273],\n",
      "          [-4.5508, -4.6250, -4.7031,  ..., -6.7227, -6.8672, -7.0078],\n",
      "          [-4.7969, -4.8672, -4.9375,  ..., -6.7891, -6.8867, -6.9883],\n",
      "          ...,\n",
      "          [-4.5586, -4.7070, -4.8555,  ..., -5.5156, -5.2891, -5.0586],\n",
      "          [-4.6367, -4.7695, -4.8984,  ..., -5.2773, -5.0352, -4.7930],\n",
      "          [-4.7109, -4.8281, -4.9453,  ..., -5.0352, -4.7812, -4.5273]]],\n",
      "\n",
      "\n",
      "        [[[-7.0859, -7.3477, -7.6094,  ..., -5.7188, -5.4570, -5.1914],\n",
      "          [-7.0664, -7.3398, -7.6133,  ..., -6.0195, -5.7383, -5.4609],\n",
      "          [-7.0469, -7.3320, -7.6133,  ..., -6.3164, -6.0234, -5.7305],\n",
      "          ...,\n",
      "          [-6.3945, -6.6133, -6.8320,  ..., -8.1953, -8.1719, -8.1562],\n",
      "          [-6.3398, -6.5508, -6.7656,  ..., -7.8867, -7.9141, -7.9414],\n",
      "          [-6.2891, -6.4922, -6.6992,  ..., -7.5781, -7.6523, -7.7227]]],\n",
      "\n",
      "\n",
      "        [[[-3.8301, -3.9121, -3.9941,  ..., -3.5234, -3.5840, -3.6426],\n",
      "          [-3.9004, -3.9453, -3.9922,  ..., -3.6465, -3.6641, -3.6816],\n",
      "          [-3.9707, -3.9805, -3.9902,  ..., -3.7695, -3.7441, -3.7188],\n",
      "          ...,\n",
      "          [-3.1719, -3.4395, -3.7090,  ..., -4.3984, -4.3359, -4.2695],\n",
      "          [-3.1172, -3.3750, -3.6348,  ..., -4.2383, -4.1094, -3.9766],\n",
      "          [-3.0625, -3.3105, -3.5586,  ..., -4.0781, -3.8809, -3.6836]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-7.8789, -7.8398, -7.8008,  ..., -8.2109, -8.0938, -7.9688],\n",
      "          [-7.9727, -7.9570, -7.9414,  ..., -8.3438, -8.2500, -8.1562],\n",
      "          [-8.0703, -8.0781, -8.0859,  ..., -8.4766, -8.4141, -8.3438],\n",
      "          ...,\n",
      "          [-7.1367, -7.2891, -7.4375,  ..., -6.9141, -6.8984, -6.8789],\n",
      "          [-7.0938, -7.1836, -7.2773,  ..., -6.8281, -6.7695, -6.7109],\n",
      "          [-7.0508, -7.0820, -7.1133,  ..., -6.7422, -6.6406, -6.5391]]],\n",
      "\n",
      "\n",
      "        [[[-6.6914, -6.9414, -7.1953,  ..., -8.1094, -7.8789, -7.6523],\n",
      "          [-6.7148, -6.9648, -7.2109,  ..., -8.3828, -8.1562, -7.9336],\n",
      "          [-6.7422, -6.9844, -7.2227,  ..., -8.6641, -8.4375, -8.2109],\n",
      "          ...,\n",
      "          [-7.0469, -7.1562, -7.2617,  ..., -7.3008, -7.1953, -7.0938],\n",
      "          [-6.9375, -7.0898, -7.2383,  ..., -7.2578, -7.1680, -7.0742],\n",
      "          [-6.8281, -7.0195, -7.2148,  ..., -7.2188, -7.1367, -7.0586]]],\n",
      "\n",
      "\n",
      "        [[[-4.1758, -4.1367, -4.0938,  ..., -4.4609, -4.3125, -4.1680],\n",
      "          [-4.3086, -4.2617, -4.2148,  ..., -4.5391, -4.4648, -4.3906],\n",
      "          [-4.4414, -4.3867, -4.3320,  ..., -4.6211, -4.6172, -4.6094],\n",
      "          ...,\n",
      "          [-4.7461, -5.0078, -5.2656,  ..., -5.2578, -5.2383, -5.2188],\n",
      "          [-4.5781, -4.8438, -5.1055,  ..., -5.0625, -4.9336, -4.8008],\n",
      "          [-4.4102, -4.6758, -4.9453,  ..., -4.8672, -4.6289, -4.3867]]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "y tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6c84a995784b2b915c83c2df332634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Attempting to unscale FP16 gradients.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-c7762dc1301c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateDataLoaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m#512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeviceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_TPU_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_native_amp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         )\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0;31m# wraps into LightingOptimizer only for running step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightningOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_lightning_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprofiler_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_optimizer_step_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[1;32m    273\u001b[0m         make_optimizer_step = self.precision_plugin.pre_optimizer_step(\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         )\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/native_amp.py\u001b[0m in \u001b[0;36mpre_optimizer_step\u001b[0;34m(self, pl_module, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;34m\" To request, please file a Github issue in PyTorch and tag @mcarilli\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mlambda_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    648\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                             result = self.training_step_and_backward(\n\u001b[0;32m--> 650\u001b[0;31m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m                             )\n\u001b[1;32m    652\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                     \u001b[0;31m# hook - call this hook only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, result, optimizer, opt_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             result.closure_loss = self.trainer.accelerator.backward(\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_accumulate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m             )\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, closure_loss, optimizer, optimizer_idx, should_accumulate, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         output = self.precision_plugin.backward(\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_accumulate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         )\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/native_amp.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, model, closure_loss, optimizer, opt_idx, should_accumulate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# unscale gradient to allow analyze within `on_after_backward`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshould_accumulate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36munscale_\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mfound_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unscale_grads_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfound_inf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSCALED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cudaTest/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_unscale_grads_\u001b[0;34m(self, optimizer, inv_scale, found_inf, allow_fp16)\u001b[0m\n\u001b[1;32m    205\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mallow_fp16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attempting to unscale FP16 gradients.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                         \u001b[0;31m# is_coalesced() == False means the sparse grad has values with duplicate indices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempting to unscale FP16 gradients."
     ]
    }
   ],
   "source": [
    "for fold in range(nfolds):\n",
    "    print(\"FOLD: \", fold)\n",
    "    \n",
    "#     ds_train = HuBMAPDataset(fold=fold, train=True, tfms=get_aug(), cache=False)\n",
    "#     ds_val = HuBMAPDataset(fold=fold, train=False, cache=False)\n",
    "    \n",
    "#     train_loader = DataLoader(ds_train, batch_size=bs, num_workers=20)\n",
    "#     val_loader = DataLoader(ds_val, batch_size=bs, num_workers=20)\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(\n",
    "       monitor='val_loss',\n",
    "       min_delta=0.00,\n",
    "       patience=10,\n",
    "       verbose=False,\n",
    "       mode='min'\n",
    "    )\n",
    "    \n",
    "    system = HubmapSystem.load_from_checkpoint(\"eff_{}.ckpt\".format(fold))\n",
    "    system.learning_rate = 0.005\n",
    "    trainer = pl.Trainer(gpus=1, precision=16, deterministic=True,callbacks=[early_stop_callback],\n",
    "                     benchmark=True, check_val_every_n_epoch=1, accumulate_grad_batches=4)\n",
    "    \n",
    "#     # Run learning rate finder\n",
    "#     lr_finder = trainer.tuner.lr_find(system, train_loader, val_loader)\n",
    "\n",
    "#     # Results can be found in\n",
    "#     lr_finder.results\n",
    "\n",
    "#     # Plot with\n",
    "#     fig = lr_finder.plot(suggest=True)\n",
    "#     fig.show()\n",
    "    \n",
    "#     system.lr = lr_finder.suggestion()\n",
    "#     print(\"LR: \", system.lr)\n",
    "\n",
    "    \n",
    "    #256\n",
    "    train_loader, val_loader = createDataLoaders(256, 4, fold)\n",
    "    \n",
    "    trainer.fit(system, train_loader, val_loader)\n",
    "    \n",
    "    #512\n",
    "    train_loader, val_loader = createDataLoaders(512, 4, fold)\n",
    "    trainer.fit(system, train_loader, val_loader)\n",
    "    \n",
    "    #1024\n",
    "    train_loader, val_loader = createDataLoaders(1024, 4, fold)\n",
    "    trainer.fit(system, train_loader, val_loader)\n",
    "    \n",
    "    trainer.save_checkpoint(f'eff_{fold}.ckpt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.model.eval()\n",
    "\n",
    "t = torch.rand([256, 256])\n",
    "\n",
    "system(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [61, 61, 61,  ..., 61, 61, 61],\n",
      "        [62, 62, 62,  ..., 62, 62, 62],\n",
      "        [63, 63, 63,  ..., 63, 63, 63]])\n",
      "torch.Size([64, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "v = torch.arange(0, 64)\n",
    "stacked = torch.stack([v]*(256**2)).T\n",
    "print(v)\n",
    "print(stacked)\n",
    "\n",
    "res = stacked.view([64, 256, 256])\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
